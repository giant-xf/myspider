# 第一天:
- 特征工程是:
  - 将原始数据转换为更好地代表预测模型的潜在问题的特征的过程，从而提高了对未知数据的模型准确性


## 字典特征抽取
- DictVectorizer(sparse=True,…)
  - DictVectorizer.fit_transform(X)
    - X:字典或者包含字典的迭代器
    - 返回值：返回sparse:矩阵
  - DictVectorizer.inverse_transform(X)
    - X:array数组或者sparse矩阵
    - 返回值:转换之前数据格式
  - DictVectorizer.get_feature_names()
    - 返回类别名称
  - DictVectorizer.transform(X)
    - 按照原先的标准转换


```python
from sklearn.feature_extraction import DictVectorizer
def dictvec():
    """
    字典数据抽取
    :return: None
    """
    # 实例化，sparse'解析'
    dict = DictVectorizer(sparse=False)

    # 调用fit_transform
    data = dict.fit_transform([{'city': '北京','temperature': 100}, {'city': '上海','temperature':60}, {'city': '深圳','temperature': 30}]
    print(dict.get_feature_names())
    print(dict.inverse_transform(data))
    print(data)
    return None
```


## 文本特征抽取

```python
def countvec():
    """
    对文本进行特征值化
    :return: None
    """
    cv = CountVectorizer()

    data = cv.fit_transform(["人生 苦短，我 喜欢 python", "人生漫长，不用 python"])

    print(cv.get_feature_names())

    print(data.toarray())

    return None
```

## TF-IDF
- TF-IDF的主要思想是：如果某个词或短语在一篇文章中出现的概率高，
并且在其他文章中很少出现，则认为此词或者短语具有很好的类别区分
能力，适合用来分类。
- TF-IDF作用：用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。

- 类：sklearn.feature_extraction.text.TfidfVectorizer



- 数值型数据：标准缩放：
  - 归一化
  - 标准化
  - 缺失值
类别型数据：one-hot编码
时间类型：时间的切分

#### 归一化：
 𝑋′=  (𝑥−𝑚𝑖𝑛)/(𝑚𝑎𝑥−𝑚𝑖𝑛)
 𝑋′′=𝑋′∗(𝑚𝑥−𝑚𝑖)+𝑚𝑖
注：作用于每一列，max为一列的最大值，min为一列的最小值,那么X’’
为最终结果，mx，mi分别为指定区间值默认mx为1,mi为0

sklearn归一化API:  sklearn.preprocessing.MinMaxScaler

- 归一化总结:
 - 注意在特定场景下最大值最小值是变化的，另外，最大值与最小值非常容易受异常点影响，所以这种方法鲁棒性较差，只适合传统精确小数据场景。

#### 标准化
特点：通过对原始数据进行变换把数据变换到均值为0,方差为1范围内
公式: 𝑋′=  (𝑥−mean)/𝜎
注：作用于每一列，mean为平均值，𝜎为标准差(考量数据的稳定性)

sklearn标准化API:  scikit-learn.preprocessing.StandardScaler

- 标准化总结
 - 在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景。


## 降维
### 特征选择：
特征选择就是单纯地从提取到的所有特征中选择部分特征作为训练集特征，
特征在选择前和选择后可以改变值、也不改变值，但是选择后的特征维数肯
定比选择前小，毕竟我们只选择了其中的一部分特征。
- 主要方法（三大武器）：
  - Filter(过滤式):VarianceThreshold
  - Embedded(嵌入式)：正则化、决策树
  - (不常用)Wrapper(包裹式)：

### 主成分降维(PCA)
 - 本质：PCA是一种分析、简化数据集的技术
 - 目的：是数据维数压缩，尽可能降低原数据的维数（复杂度），损失少量信息。
 - 作用：可以削减回归分析或者聚类分析中特征的数量
 一般按小数降维

```python
from sklearn.decomposition import PCA
def pca():
    """
    主成分分析进行特征降维
    :return: None
    """
    pca = PCA(n_components=0.9)
    data = pca.fit_transform([[2,8,4,5],[6,3,0,8],[5,4,9,1]])
    print(data)
    return None
```
